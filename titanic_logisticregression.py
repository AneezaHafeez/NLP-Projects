# -*- coding: utf-8 -*-
"""Titanic-logisticRegression.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qC5KOC4UI9rtdBiRaC8fPCBJTrGurA5f
"""

from google.colab import drive

import pandas as pd
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder,OneHotEncoder,StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.compose import make_column_transformer
from sklearn.impute import SimpleImputer
from sklearn.pipeline import Pipeline
from sklearn.pipeline import make_pipeline

from pandas.io.parsers.readers import read_csv
path1="/content/drive/MyDrive/Compressed/train.csv"
path2="/content/drive/MyDrive/Compressed/test.csv"
train_data=pd.read_csv(path1)
test_data=pd.read_csv(path2)

train_data.isnull().sum()
print("Train Shape:",train_data.shape)
test_data.isnull().sum()
print("Test Shape:",test_data.shape)

train_data.info()

encoder = LabelEncoder()
X_train["Sex"] = encoder.fit_transform(X_train["Sex"])

selected_features = ["Pclass", "Sex", "Age", "SibSp", "Parch", "Fare"]
X_train = train_data[selected_features]
y_train = train_data["Survived"]

combined_data = pd.concat([X_train, test_data[selected_features]], axis=0)

numeric_features = ["Age"]
numeric_transformer = Pipeline(steps=[
    ("imputer", SimpleImputer(strategy="mean")),
    ("scaler", StandardScaler())
])

categorical_features = ["Sex", "Pclass"]
categorical_transformer = Pipeline(steps=[
    ("imputer", SimpleImputer(strategy="most_frequent")),
    ("encoder", OneHotEncoder(handle_unknown="ignore"))
])

preprocessor = ColumnTransformer(
    transformers=[
        ("numeric", numeric_transformer, numeric_features),
        ("categorical", categorical_transformer, categorical_features)
    ])

X_train,X_test,y_train,y_test=train_test_split(X_train,y_train,test_size=0.2, random_state=42)

X_train_processed = preprocessor.fit_transform(X_train)

from sklearn.linear_model import LogisticRegression

model = LogisticRegression()
model.fit(X_train_processed, y_train)

# Perform the same preprocessing steps on the test data
X_test_processed = preprocessor.transform(X_test)

# Make predictions on the test data
y_test_pred = model.predict(X_test_processed)

# Generate predictions for the survival of passengers in the test dataset
test_passenger_ids = test_data["PassengerId"]
predictions_df = pd.DataFrame({"PassengerId": test_passenger_ids, "Survived": y_test_pred})
predictions_df.to_csv("predictions.csv", index=False)

X_val_processed = preprocessor.transform(X_val)

# Make predictions on the validation data
y_val_pred = model.predict(X_val_processed)
accuracy = accuracy_score(y_val, y_val_pred)
print("Validation Accuracy:", accuracy)

from sklearn.metrics import classification_report

# Model Evaluation - Classification Report
classification_report = classification_report(y_val, y_val_pred)
print("Classification Report:\n", classification_report)

import matplotlib.pyplot as plt

train_data["FamilySize"] = train_data["SibSp"] + train_data["Parch"] + 1
family_survival_counts = train_data.groupby(["FamilySize", "Survived"]).size().unstack()

# Plot the number of family members who survived and did not survive
family_survival_counts.plot(kind="bar", stacked=True)
plt.xlabel("Family Size")
plt.ylabel("Count")
plt.title("Survival Count by Family Size")
plt.legend(["Did Not Survive", "Survived"])
plt.show()